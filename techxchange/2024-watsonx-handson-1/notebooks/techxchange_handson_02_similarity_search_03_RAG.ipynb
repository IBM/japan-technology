{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de784795-f749-44a9-9925-34364836c94c"
   },
   "source": [
    "# TechXchange Japan 2024: さわってみようベクトル・データベース watsonx.dataでRAG体験\n",
    "\n",
    "\n",
    "生成AIの回答精度を向上させるために、自社内のデータを活用してみましょう！<br>\n",
    "ベクトル・データベース + 大規模言語モデル（LLM）で構成されるRAGのアーキテクチャーを使えば、自社内の情報で生成AIチャットボットが作成できます。<br>\n",
    "当ハンズオンでは「TechXchange Japan 2024」に関するデータを使ってRAGを構成し、「TechXchange Japan 2024」に関することを教えてくれるチャットボットを作成します。<br>\n",
    "(以下ベクトル・データベースはベクトルDBと表記します。)<br>\n",
    "\n",
    "\n",
    "具体的には大規模言語モデル（LLM）を使用したアプリケーション開発のためのオープンソース・オーケストレーション・フレームワーク[LangChain](https://python.langchain.com/docs/introduction/)を使って、wastosonx.dataのベクトルDB **Milvus**に「TechXchange Japan 2024」に関するデータをロードし、watson.aiで提供されているLLMを使用してRAGを構成し、「TechXchange Japan 2024」のことを回答してくれるChatbotを作ってみます。\n",
    "\n",
    "ハンズオンは以下の順序で実行します:\n",
    "\n",
    "1. Excelをベクトル化してベクトルDB Milvusに入れよう！\n",
    "2. **ベクトルDB Milvusに入ったデータで類似検索してみよう!** [**当notebook**]\n",
    "3. **ベクトルDB Milvusとwatsonx.ai LLMでRAGを構成して、質問をしてみよう!** [**当notebook**]\n",
    "4. ベクトルDB Milvusとwatsonx.ai LLMでRAGを構成して、チャットアプリを作成してみよう!\n",
    "\n",
    "**当notebookは2と3を実施します。**<br>\n",
    "\n",
    "このハンズオンのガイドは[**こちら**](https://ibm.biz/20241127-rag-handson)にあります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad301095-8005-42d8-9258-ea98e092a38a"
   },
   "source": [
    "## 2. ベクトルDB Milvusに入ったデータで類似検索してみよう! \n",
    "\n",
    "\n",
    "<img  src=\"https://github.com/IBM/japan-technology/blob/main/techxchange/2024-watsonx-handson-1/images/notebook02_01.jpg?raw=true\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**実行は　セルを選択(クリック)して**\n",
    "\n",
    "- **Windows： Ctrl + Enter** \n",
    "- **Mac: ⌘ (command) + Enter 　または Ctrl + Enter**\n",
    "\n",
    "**実行して次のセルを選択は　セルを選択(クリック)して**\n",
    "\n",
    "- **Windows： Shift + Enter** \n",
    "- **Mac: Shift + Enter**\n",
    "\n",
    "セルの左側に[*]が表示されている場合は実行中です。<br>\n",
    "[1]のように数字が入っている場合は、実行が完了しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b35cf2d1-5d74-4357-bb8e-d35d094cb2eb"
   },
   "source": [
    "### 1. 必要なライブラリーのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73118d28-e88b-4974-bd30-afe87a57e9d6"
   },
   "outputs": [],
   "source": [
    "print(\"pip install start\")\n",
    "!pip install -Uq 'ibm-watsonx-ai>=1.1.15'\n",
    "!pip install -Uq 'langchain>=0.3.3'\n",
    "!pip install -Uq 'langchain-ibm>=0.3.1'\n",
    "!pip install -Uq 'langchain-milvus>=0.1.6'\n",
    "!pip install -Uq 'langchain-community>=0.3.2'\n",
    "!pip install -Uq 'pymilvus>=2.4.8'\n",
    "print(\"pip install completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c171cc9-8a87-4242-a04e-08d132ef77a2"
   },
   "source": [
    "### 2. apikeyの設定 \n",
    "\n",
    "- 実行するとテキスト入力ボックスが表示されるので、事前に取得したapikeyをに入れてEnter Keyを押してください\n",
    "\n",
    "- ハンズオン環境で実行の場合は、`IBM Cloud Service API key`を入力してください。　よくわからない場合は[こちら](https://github.com/IBM/japan-technology/tree/main/techxchange/2024-watsonx-handson-1/01_techzone_use_environments.md)の2-3を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ceb4ec5-7ad9-4a0f-ab6f-b14ea9902948"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "apikey = getpass.getpass(\"apikeyを入れてEnter Keyを押してください:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9621738-d9da-4903-9748-46ce74b61a02"
   },
   "source": [
    "### 3. Milvus接続情報の設定\n",
    "\n",
    "実行すると順に以下の2つのテキスト入力ボックスが表示されるので、事前に取得したMilvus接続情報の値を入力してください。\n",
    "- milvus GRPC ホストを入れてEnter Keyを押してください →  GRPC ホストの値を入力  \n",
    "\n",
    "- milvus GRPC ポートを入れてEnter Keyを押してください　→ GRPC ポートの値をを入力\n",
    "\n",
    "\n",
    "Milvus接続情報の詳細取得手順は[こちら](https://github.com/IBM/japan-technology/tree/main/techxchange/2024-watsonx-handson-1/watsonx_data_get_milvus_info.md) を参照\n",
    "\n",
    "簡略な接続手順は以下です:\n",
    "- watsonx.dataの画面を開く\n",
    "- ナビゲーションメニューから「インフラストラクチャー・マネージャー」を選択\n",
    "- サービス「Milvus」をクリック\n",
    "- タイプの下の「接続の詳細を見る」をクリック\n",
    "- GRPC ホストの値とGRPC ポートの値を取得\n",
    "  \n",
    "collection名は`techxchange_line_data`としています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3b06197-1c20-49c3-89f7-3156928e2b1e"
   },
   "outputs": [],
   "source": [
    "milvus_host=input(\"milvus GRPC ホストを入れてEnter Keyを押してください: \")\n",
    "milvus_port=input(\"milvus GRPC ポートを入れてEnter Keyを押してください: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b4db79f-0921-4da1-a44b-79c7a9e5bc0f"
   },
   "outputs": [],
   "source": [
    "# Milvus接続情報パラメータののセット\n",
    "my_connection_args ={\n",
    " 'uri': f'https://{milvus_host}:{milvus_port}', \n",
    " 'token': f'ibmlhapikey:{apikey}'\n",
    "}\n",
    "\n",
    "my_collection =  'techxchange_line_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4497a59-b1b5-4cc9-9c03-7b7e18425ebc"
   },
   "source": [
    "### 4. watsonx.ai Project idの設定\n",
    "\n",
    "Watson Studioで実行する場合は、このノートブックが実行されるプロジェクトからProject idを取得します。\n",
    "Watson Studio以外で実行する場合は、Project idを入力してください。\n",
    "\n",
    "**Hint**: `project_id` はプロジェクトを表示し、管理タブから `project_id` を取得可能です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37d931e7-e926-439f-989f-bf9ce30fb4bd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Project idを入力してください (入力後enter): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33149605-4856-4e99-ab34-af0a2218eff0"
   },
   "source": [
    "### 5.watsonx.aiのAuthentication用のエンドポイントのURLの設定\n",
    "\n",
    "Waston Machine Learningのインスタンスを作成したリージョンで決まります。\n",
    "https://ibm.github.io/watson-machine-learning-sdk/setup_cloud.html#authentication　より\n",
    "\n",
    "- Dallas: https://us-south.ml.cloud.ibm.com\n",
    "- London: https://eu-gb.ml.cloud.ibm.com\n",
    "- Frankfurt: https://eu-de.ml.cloud.ibm.com\n",
    "- Tokyo: https://jp-tok.ml.cloud.ibm.com\n",
    "\n",
    "今回はダラスのWaston Machine Learningのインスタンスを使っているので`https://us-south.ml.cloud.ibm.com`を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "198412c3-1360-4df1-977e-4ec12bbb23a4"
   },
   "outputs": [],
   "source": [
    "watsonx_url = \"https://us-south.ml.cloud.ibm.com\" #watsonx.aiのAuthentication用のエンドポイントのURL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dd48de7-ae9a-420a-9de3-9ba33c1f429b"
   },
   "source": [
    "### 6. 必要ライブラリーのImport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a2b3fae-312a-4bb9-9314-1a1a37dea809"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema.document import Document\n",
    "import json\n",
    "from langchain_milvus import Milvus\n",
    "import os\n",
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "848a8cdb-cb32-482a-9aed-0a3c0f6d5f1d"
   },
   "source": [
    "### 7. Embeddingモデルの取得\n",
    "ベクトル化した時と同じモデル`intfloat/multilingual-e5-large`を使います<br>\n",
    "- https://huggingface.co/intfloat/multilingual-e5-large\n",
    "- https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models-embed.html?context=wx&locale=ja#multilingual-e5-large\n",
    "\n",
    "LangChainで使用できるwatsonx.aiのEmbeddingモデル`intfloat/multilingual-e5-large`があるので、今回はこちらを使用します:\n",
    "- https://python.langchain.com/docs/integrations/text_embedding/ibm_watsonx/\n",
    "  \n",
    "---\n",
    "\n",
    ">尚、`intfloat/multilingual-e5-large`はオープンソースで公開されているので、watsonx.aiのEmbeddingモデルを使用しなくとも、ローカルにダウンロードすることで使用可能です。\n",
    "その場合のコードはこちらです(今回は使用しません)\n",
    "\n",
    ">```python\n",
    ">from langchain_huggingface import HuggingFaceEmbeddings\n",
    ">from tqdm.autonotebook import tqdm\n",
    ">embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    ">```\n",
    "> 上記コード実行時の`TqdmExperimentalWarning`のWarningは無視でよいです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0cf8eef-ec2a-4195-99e6-c23140e47d2b"
   },
   "outputs": [],
   "source": [
    "# watsonx.aiのEmbeddingモデル取得\n",
    "embed_params = {\n",
    "    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 512,\n",
    "    EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "}\n",
    "\n",
    "embeddings = WatsonxEmbeddings(\n",
    "    model_id=\"intfloat/multilingual-e5-large\",\n",
    "    url=watsonx_url ,\n",
    "    apikey=apikey,\n",
    "    project_id=project_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a643608-e108-4932-8e94-4a0631b874ac"
   },
   "source": [
    "### 8.  ベクトルDB Milvusに接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3655cc28-7d24-4437-9e1c-9de6b30392fc"
   },
   "outputs": [],
   "source": [
    "from langchain_milvus import Milvus\n",
    "\n",
    "vector_store = Milvus(\n",
    "    embeddings,\n",
    "    connection_args =my_connection_args,\n",
    "    collection_name = my_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "906f6ad1-265d-4ab5-a613-143af4093394"
   },
   "source": [
    "### 9.  挿入データの確認\n",
    "\n",
    "Milvus DBにロードした内容をDataFrameにダンプして表示させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10cbd80d-950e-40df-aafa-9d83c8023cc6"
   },
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import pandas as pd\n",
    "\n",
    "pk_list=vector_store.get_pks(expr=\"pk > 0\")\n",
    "\n",
    "client = MilvusClient(uri=my_connection_args['uri'], token=my_connection_args['token'])\n",
    "\n",
    "res = client.get(\n",
    "    collection_name= my_collection,\n",
    "    ids=pk_list\n",
    ")\n",
    "\n",
    "for i, milvus_rec in enumerate(res):\n",
    "    vecter_data = milvus_rec['vector']\n",
    "    res[i]['vector']= \"[\"+\", \".join(map(str, vecter_data))+\"]\"\n",
    "    res[i]['pk']= str(milvus_rec['pk'])\n",
    "\n",
    "\n",
    "df_s = pd.DataFrame.from_dict(res).reindex(columns=['ID', 'Category', 'text', 'pk', 'vector'])\n",
    "df_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6a61620-ca5e-41aa-96fc-fa834b6a486c"
   },
   "source": [
    "### 10. ベクトルDBでテキスト類似検索してみます\n",
    "\n",
    "参考: LangChain ドキュメント: [Vector stores → Search ](https://python.langchain.com/docs/concepts/vectorstores/#search)\n",
    "\n",
    "基本、類似度が高い順でリストされます。いろいろなオプションで検索してみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8eff727-3251-4d18-8068-1c265bc98ced"
   },
   "source": [
    "#### 10-1. similarity_search: オプションなし デフォルト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b5b9cc0-1e71-4b64-8182-ae4de00b7ed2"
   },
   "outputs": [],
   "source": [
    "# オプションなし\n",
    "query = \"IBM TechXchange Japanとは?\"\n",
    "docs = vector_store.similarity_search(query)\n",
    "\n",
    "for doc in docs:\n",
    "    print({\"content\": doc.page_content[0:100], \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01b8ed37-efd3-481a-87b7-4e6edf500e20"
   },
   "source": [
    "#### 10-2. similarity_search: 結果の取得数をkで指定(デフォルトは4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4400ee40-db77-46cd-8115-524d749d795a"
   },
   "outputs": [],
   "source": [
    "# 結果の取得数をkで指定(デフォルトは4)\n",
    "\n",
    "docs = vector_store.similarity_search(query, k=10)\n",
    "\n",
    "for doc in docs:\n",
    "    print({\"content\": doc.page_content[0:100], \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00e1a233-31e4-44d0-9d6a-a9c99875a15f"
   },
   "source": [
    "#### 10-3. similarity_search_with_score: 類似度のスコアも一緒に出力\n",
    "- 類似度のスコアも一緒に出してみます\n",
    "- スコアはコサイン類似度の場合は、1に近いほど類似度が高いです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11061ede-3f1d-4022-9825-56431ef481f7"
   },
   "outputs": [],
   "source": [
    "# 類似度のスコアも一緒に出してみます\n",
    "# スコアはコサイン類似度の場合は、1に近いほど類似度が高いです。\n",
    "\n",
    "docs = vector_store.similarity_search_with_score(query, k=10)\n",
    "for doc, score in docs:\n",
    "    print({\"score\": score, \"content\": doc.page_content[0:100], \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf04ab86-bebc-4d88-913c-b6f1d253a7de"
   },
   "source": [
    "#### 10-4. similarity_search_with_score exprオプション: 'Category': '概要'　でフィルター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6db9ffcf-5763-4d3f-9e6d-653b7970384f"
   },
   "outputs": [],
   "source": [
    "# 'Category': '概要'　でフィルターしてみます\n",
    "docs = vector_store.similarity_search_with_score(query, k=10, expr=\"Category=='概要'\")\n",
    "for doc, score in docs:\n",
    "    print({\"score\": score, \"content\": doc.page_content[0:100], \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26c4f158-97dc-458f-9ecc-211c89f45aa1"
   },
   "source": [
    "### これで「2. ベクトルDB Milvusに入ったデータで類似検索してみよう!」は完了です。<br>\n",
    "### 次の「3. ベクトルDB Milvusとwatsonx.ai LLMでRAGを構成して、質問をしてみよう!」に進みます\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c407657-889a-4b1a-a7d0-0f03bb9cf07c"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ベクトルDB Milvusとwatsonx.ai LLMでRAGを構成して、質問をしてみよう!\n",
    "\n",
    "<img  src=\"https://github.com/IBM/japan-technology/blob/main/techxchange/2024-watsonx-handson-1/images/notebook03_01.jpg?raw=true\">\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6409e2c-1bd4-4b9a-b78b-fd04432a2417"
   },
   "source": [
    "### 1.  watsonx.ai LLMの取得\n",
    "\n",
    "今回は[mixtral-8x7b-instruct-v01](https://www.ibm.com/docs/ja/watsonx/saas?topic=solutions-supported-foundation-models#mixtral-8x7b-instruct-v01)を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a64ffd1-bba0-49b8-9582-0914e2567487"
   },
   "outputs": [],
   "source": [
    "# watsonx.ai LLM: 必要なライブラリーのImport\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "# 使用するLLMのパラメータ\n",
    "generate_params = {\n",
    "    GenParams.MAX_NEW_TOKENS: 16384,\n",
    "    GenParams.MIN_NEW_TOKENS: 0,\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.REPETITION_PENALTY: 1\n",
    "}\n",
    "\n",
    "# LangChainで使うllm\n",
    "custom_llm = WatsonxLLM(\n",
    "    model_id=\"mistralai/mixtral-8x7b-instruct-v01\",\n",
    "    url=watsonx_url,\n",
    "    apikey=apikey,\n",
    "    project_id=project_id,\n",
    "    params=generate_params,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f5e7615-c6e7-44d5-a3f6-5249b4cf0760"
   },
   "source": [
    "### 2. ベクトルデータベースからLangChain Retrieverの作成\n",
    "\n",
    "参考: LangChain ドキュメント: [Retrievers](https://python.langchain.com/docs/concepts/retrievers/)\n",
    "\n",
    "Retrieverは検索のレスポンスを返すlangchainのInterfaceです。<br>\n",
    "主にベクトルストアから作成可能ですが、Wikipedia検索などからでも作成できます。<br>\n",
    "Retrieverを使うとLLMと組み合わせたRAG構成がLangChainで簡単にできます。<br>\n",
    "「2. ベクトルDB Milvusに入ったデータで類似検索してみよう! 」で使用したvector storeとの違いは以下です:\n",
    "- vector storeは1つ種類のベクトルDBに特化したもの。今回はMilvusのvector storeを使用しています。\n",
    "- RetrieverはベクトルDBおよび他の検索システムに汎用的に使用できるインターフェースであり、query文字列を入力としLangchainのDocumentのListを出力する単純なものです。Chainを構成することができるため、RAG構成でよく使用されます。\n",
    "\n",
    "ここではいろいろな条件のRetrieverをベクトルDBから作成してみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85b9acc3-598a-4b76-83b6-00d94c623e73"
   },
   "source": [
    "#### 2-1. as_retriever: オプションなし デフォルト構成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18624eb6-caf8-4401-a8ee-e5e0a6b04a02"
   },
   "outputs": [],
   "source": [
    "# オプションなし デフォルト構成\n",
    "query = \"IBM TechXchange Japanとは?\"\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# retriever を使用したベクトルDBの類似検索\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "for doc in docs:\n",
    "    print({\"content\": doc.page_content[0:100], \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0d7580f-5938-41e8-8680-44dc48e57a7f"
   },
   "source": [
    "#### 2-2.  as_retriever: 結果の取得数をkで指定(デフォルトは4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "490c2534-f177-412a-97ef-933fc1264d2a"
   },
   "outputs": [],
   "source": [
    "# 結果の取得数をkで指定(デフォルトは4)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "for doc in docs:\n",
    "    print({\"content\": doc.page_content[0:100], \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f7bb246-319c-4dd8-91bd-8920a09bef63"
   },
   "source": [
    "#### 2-3.   類似スコアの閾値を設定し、その閾値以上のスコアを持つ文書のみを返す\n",
    "langchain_milvus.Mivusにはsearch_type=\"similarity_score_threshold\"の設定がありません。<br>\n",
    "参考: [Similarity score threshold retrieval](https://python.langchain.com/docs/how_to/vectorstore_retriever/#similarity-score-threshold-retrieval) はlangchain_milvus v2.4.8では使えません\n",
    "\n",
    "自分で「閾値以上の類似スコアを持つ文書のみを返す」CustomRetrieverを作成すれば可能です。\n",
    "\n",
    "##### 2-3-1. CustomRetrieverの作成\n",
    "閾値以上の類似スコアを持つ文書のみを返す」CustomRetrieverを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5130dff-686d-4187-9204-4a74303621d8"
   },
   "outputs": [],
   "source": [
    "# 閾値以上の類似スコアを持つ文書のみを返す」CustomRetrieverを作成\n",
    "# asyncの方は省略\n",
    "from langchain.schema.vectorstore import VectorStoreRetriever\n",
    "from langchain.schema.document import Document\n",
    "from langchain.callbacks.manager import (\n",
    "    CallbackManagerForRetrieverRun,\n",
    ")\n",
    "from typing import List\n",
    "\n",
    "class CustomRetriever(VectorStoreRetriever):\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        top_k = self.search_kwargs.get(\"k\", 4)\n",
    "        docs_and_similarities = self.vectorstore.similarity_search_with_score(query, k=top_k)\n",
    "                \n",
    "        threshold = self.search_kwargs.get(\"score_threshold\", 0)\n",
    "       \n",
    "        return [doc for doc, score in docs_and_similarities if score >= threshold and score <= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "558423be-b4c6-4715-9462-4f6b4135d850"
   },
   "source": [
    "##### 2-3-2. CustomRetriever使用: 類似スコア 0.85以上のもの、　上位最大5件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "974be3f7-021a-4306-acfa-eebdad4f707a"
   },
   "outputs": [],
   "source": [
    "# 類似スコア 0.85以上のもの、　上位最大5件\n",
    "retriever = CustomRetriever(\n",
    "    vectorstore = vector_store,\n",
    "    search_kwargs={\"score_threshold\": 0.85, \"k\":5},\n",
    ")\n",
    "docs = retriever.invoke(query)\n",
    "# print(docs)\n",
    "for doc in docs:\n",
    "    print({\"content\": doc.page_content, \"metadata\": doc.metadata} )\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a885ad2-acb9-400f-85a7-9cd635fcb8aa"
   },
   "source": [
    "### 3. ベクトル・データベース ＋ 生成AI(LLM)のRAG構成で質問に回答してみよう\n",
    "\n",
    "プロンプトを準備してベクトル・データベースの検索結果を使って質問に回答してみましょう。<br>\n",
    "ベクトル・データベースの検索結果取得には7で作成したRetrieverを使います。<br>\n",
    "watsonx.ai LLMは1で取得しています。<br>\n",
    "LangChainのchainという機能を使って、組み合わせます。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e55b2e7-01fb-40f6-a730-78f401956477"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# retrieverは単純なデフォルトのものにします（変えてもOK）\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Prompt Templateを設定します。これはmixtral-8x7b-instruct-v01に合わせて作成してあります\n",
    "template = \"\"\"<s> [INST] \n",
    "あなたは親切で、礼儀正しく、誠実なアシスタントです。常に安全を保ちながら、できるだけユーザーの役に立つように詳しく回答してください。\n",
    "回答には、有害、非倫理的、⼈種差別的、性差別的、有毒、危険、または違法なコンテンツを含めてはいけません。回答は社会的に偏⾒がなく、本質的に前向きなものであることを確認してください。\n",
    "質問が意味をなさない場合、または事実に⼀貫性がない場合は、正しくないことに答えるのではなく、その理由を説明してください。質問の答えがわからない場合は、誤った情報を共有しないでください。\n",
    "questionに答えるために、以下のcontextを使用し必ず日本語でanswerを作成してください。\n",
    "必ず⽇本語の文章で回答してください。知ったかぶりをしないでください。\n",
    "回答を書くときは、context内の単語をできるだけ使⽤してください。context中に質問に対する回答がない場合は、「文書中に質問に対する回答が明記されていません。」とだけ回答してください。「文書中に質問に対する回答が明記されていません。」と回答した場合、そこで回答を終わりにしてください。\n",
    "contextの内容がブランクの場合、「文書中に質問に対する回答が明記されていません。」とだけ回答してください。\n",
    "セッションについて回答する場合は、タイトル、開始時刻、終了時刻、会場、概要、レベルを回答してください。回答が200文字以上の場合、回答はなるべく箇条書きを含めてわかりやすく回答してください。\n",
    "[/INST]\n",
    "</s>\n",
    "<s> [INST] 質問が質問の文章ではなく意味がわからない場合[/INST]もう少し詳しく説明していただけますか？</s>\n",
    "\n",
    "context: {context}\n",
    "question: {question}\n",
    "answer: \n",
    "\"\"\"\n",
    "\n",
    "# Prompt Templateを作成します\n",
    "rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# chainを作成します\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | custom_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4476b2c-21cb-4d48-bd31-b21b35ef4e20"
   },
   "source": [
    "ではTechXchangeに関する質問をしてみましょう！<br>\n",
    "`rag_chain.invoke(<質問文>)`　でRAGの仕組みでベクトル検索の結果から生成AIが文章を作成し回答します。\n",
    "\n",
    "お好みの質問文で置き換えるか、コメント`#` を外して質問してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "502722a3-89bb-455e-86c4-fe762451ce3f"
   },
   "outputs": [],
   "source": [
    "query=\"RAGに関するセッションの詳細を教えてください\"\n",
    "# query=\"watsonx.dataに関するセッションの詳細を教えてください\"\n",
    "# query=\"TechXchangeについて概要を教えてください\"\n",
    "# query=\"量子コンピューター関連のセッションを教えてください\"\n",
    "print(rag_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37a82467-5411-4def-8da3-3f9fee27af00"
   },
   "source": [
    "---\n",
    "(オプション) ためしに情報をベクトルDBに入れていない、TechXchangeとは関係ない一般的な質問をしてみましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e9a8dfc-174b-4696-980e-5d5c8ec14c0d"
   },
   "outputs": [],
   "source": [
    "query=\"日本の首都はどこですか?\"\n",
    "print(rag_chain.invoke(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b63ad21a-4bec-40a6-880c-906da3f834e7"
   },
   "source": [
    "ベクトルDBに入れていない情報は回答しないようにプロンプトで指示しているので、回答しません。これで不正確な回答が防げます。<br>\n",
    "ただしLLMによってそのような指示を書いても、無視するものもあったり、書き方で回答が変わったりするので、テストでプロンプトを調整したり、必要に応じて不要な回答をなくす後処理を追加してください。\n",
    "\n",
    "\n",
    "---\n",
    "### これで「3. ベクトルDB Milvusとwatsonx.ai LLMでRAGを構成して、質問をしてみよう!」は完了です。<br>\n",
    "\n",
    "\n",
    "#### Notebookを保存する場合は、右上の保存アイコンをクリックして保存してください。\n",
    "\n",
    "- <img width=\"400\" alt=\"\" src=\"https://github.com/IBM/japan-technology/blob/main/techxchange/2024-watsonx-handson-1/images/save_notebook.jpg?raw=true\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### プロジェクトの画面に戻る場合は、右上のプロジェクト名をクリックしてください。\n",
    "\n",
    "- <img width=\"400\" alt=\"\" src=\"https://github.com/IBM/japan-technology/blob/main/techxchange/2024-watsonx-handson-1/images/return_to_project.jpg?raw=true\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### Notebookを開いたままでプロジェクトの画面を表示するには、上部のプロジェクト名を右クリックし、「新しいタブで開く」でプロジェクトを新しいタブで開いてください。\n",
    "\n",
    "- <img width=\"500\" alt=\"\" src=\"https://github.com/IBM/japan-technology/blob/main/techxchange/2024-watsonx-handson-1/images/open_project_from_notebook.jpg?raw=true\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### 次の「4. ベクトル・データベース Milvusとwatsonx.ai LLMでRAGを構成して、チャットアプリを作成してみよう!」に進んでください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
