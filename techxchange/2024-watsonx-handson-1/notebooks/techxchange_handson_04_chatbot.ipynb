{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"30f97e0a-bdbf-49f2-b7ae-dff2126b2fdf"},"source":["# TechXchange Japan 2024: さわってみようベクトル・データベース watsonx.dataでRAG体験\n","\n","\n","生成AIの回答精度を向上させるために、自社内のデータを活用してみましょう！<br>\n","ベクトル・データベース + 大規模言語モデル（LLM）で構成されるRAGのアーキテクチャーを使えば、自社内の情報で生成AIチャットボットが作成できます。<br>\n","当ハンズオンでは「TechXchange Japan 2024」に関するデータを使ってRAGを構成し、「TechXchange Japan 2024」に関することを教えてくれるチャットボットを作成します。<br>\n","(以下ベクトル・データベースはベクトルDBと表記します。)<br>\n","\n","\n","具体的には大規模言語モデル（LLM）を使用したアプリケーション開発のためのオープンソース・オーケストレーション・フレームワーク[LangChain](https://python.langchain.com/docs/introduction/)を使って、wastosonx.dataのベクトルDB **Milvus**に「TechXchange Japan 2024」に関するデータをロードし、watson.aiで提供されているLLMを使用してRAGを構成し、「TechXchange Japan 2024」のことを回答してくれるChatbotを作ってみます。\n","\n","ハンズオンは以下の順序で実行します:\n","\n","1. Excelをベクトル化してベクトル・データベース Milvusに入れよう！\n","1. ベクトル・データベース Milvusに入ったデータで類似検索してみよう! \n","1. ベクトル・データベース Milvusとwatsonx.ai LLMでRAGを構成して、質問をしてみよう! \n","1. ベクトル・データベース Milvusとwatsonx.ai LLMでRAGを構成して、チャットアプリを作成してみよう!  [**当notebook**]\n","\n","\n","## 4.ベクトル・データベース Milvusとwatsonx.ai LLMでRAGを構成して、チャットアプリを作成してみよう! "]},{"cell_type":"markdown","metadata":{"id":"b35cf2d1-5d74-4357-bb8e-d35d094cb2eb"},"source":["### 1. 必要なライブラリーのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73118d28-e88b-4974-bd30-afe87a57e9d6"},"outputs":[],"source":["!pip install -Uq 'ibm-watsonx-ai>=1.1.15'\n","!pip install -Uq 'langchain>=0.3.3'\n","!pip install -Uq 'langchain-ibm>=0.3.1'\n","!pip install -Uq 'langchain-huggingface>=0.1.0'\n","!pip install -Uq 'langchain-milvus>=0.1.6'\n","!pip install -Uq 'langchain-community>=0.3.2'\n","!pip install -Uq 'pymilvus>=2.4.8\n","!pip install -Uq gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4e2b0786-639c-47af-a285-cadbf48d1067","scrolled":true},"outputs":[],"source":["# エラーが出るので一応整合性確認\n","!pip check"]},{"cell_type":"markdown","metadata":{"id":"7182c48f-86a8-4cfd-934e-911c99778b0b"},"source":["`langchain-chroma`と`langchain-elasticsearch`は今回使用していないので問題ないです。<br>\n","**インストール終了後、一旦カーネルを再起動してください**"]},{"cell_type":"markdown","metadata":{"id":"f7ea1850-535b-424b-bf95-7c9a30dd56c6"},"source":["### 2. apikeyの設定 \n","\n","- 事前に取得したapikeyを<api_key>　に入れる\n","    - 例:  `apikey=\"YyyyyyyyXxxxxxxxxxxxxZzzzzzzzzzzzzz\"`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffc85fc5-1af5-4114-8c51-07a56287d723"},"outputs":[],"source":["apikey=\"<api_key>\""]},{"cell_type":"markdown","metadata":{"id":"c9621738-d9da-4903-9748-46ce74b61a02"},"source":["### 3. Milvus接続情報の設定\n","\n","- watsonx.dataの画面を開く\n","- ナビゲーションメニューから「インフラストラクチャー・マネージャー」を選択\n","- サービス「Milvus」をクリック\n","- タイプの下の「接続の詳細を見る」をクリック\n","- GRPC ホストの値を<milvus GRPC ホスト>　に入れる\n","    - 例:  `milvus_host=\"xxxxxxxxxxx-xxxxxxxxxxx-xxxxxxxx.xxxxxxxx.lakehouse.appdomain.cloud\"`\n","- GRPC ポートの値を<milvus GRPC ポート>　に入れる\n","    - 例:  `milvus_port=\"9999\"`\n","      \n","collection名は`techxchange_line_data`としています。"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4b4db79f-0921-4da1-a44b-79c7a9e5bc0f"},"outputs":[],"source":["milvus_host=\"<milvus GRPC ホスト>\"\n","milvus_port=\"<milvus GRPC ポート>\"\n","\n","my_connection_args ={\n"," 'uri': f'https://{milvus_host}:{milvus_port}', \n"," 'token': f'ibmlhapikey:{apikey}'\n","}\n","my_collection =  'techxchange_line_data'"]},{"cell_type":"markdown","metadata":{"id":"45a22cc1-58cb-4ce5-aee9-7518c9c8b803"},"source":["### 3. watsonx.ai Project idの設定\n","\n","Watson Studioで実行する場合は、このノートブックが実行されるプロジェクトからProject idを取得します。\n","Watson Studio以外で実行する場合は、Project idを入力してください。\n","\n","**Hint**: `project_id` はプロジェクトを表示し、管理タブから `project_id` を取得可能です."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"db063c74-f624-475b-b351-11cc27935bae"},"outputs":[],"source":["import os\n","try:\n","    project_id = os.environ[\"PROJECT_ID\"]\n","except KeyError:\n","    project_id = input(\"Project idを入力してください (入力後enter): \")"]},{"cell_type":"markdown","metadata":{"id":"754832b9-f4bd-4df0-ab5a-4992aa70bae1"},"source":["### 5.watsonx.aiのAuthentication用のエンドポイントのURLの設定\n","\n","Waston Machine Learningのインスタンスを作成したリージョンで決まります。\n","https://ibm.github.io/watson-machine-learning-sdk/setup_cloud.html#authentication　より\n","\n","- Dallas: https://us-south.ml.cloud.ibm.com\n","- London: https://eu-gb.ml.cloud.ibm.com\n","- Frankfurt: https://eu-de.ml.cloud.ibm.com\n","- Tokyo: https://jp-tok.ml.cloud.ibm.com\n","\n","今回はダラスのWaston Machine Learningのインスタンスを使っているので`https://us-south.ml.cloud.ibm.com`を使います。"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cfd52f14-a187-4a1d-9f40-abb4437d02a2"},"outputs":[],"source":["watsonx_url = \"https://us-south.ml.cloud.ibm.com\" #watsonx.aiのAuthentication用のエンドポイントのURL"]},{"cell_type":"markdown","metadata":{"id":"3dd48de7-ae9a-420a-9de3-9ba33c1f429b"},"source":["### 4. 必要ライブラリーのImport"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5a2b3fae-312a-4bb9-9314-1a1a37dea809"},"outputs":[],"source":["import pandas as pd\n","from langchain.schema.document import Document\n","import json\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_milvus import Milvus\n","import os\n","from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n","from langchain_ibm import WatsonxLLM\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"848a8cdb-cb32-482a-9aed-0a3c0f6d5f1d"},"source":["### 4. Embeddingモデルの取得\n","ベクトル化した時と同じモデル`intfloat/multilingual-e5-large`を使います<br>\n","https://huggingface.co/intfloat/multilingual-e5-large"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"d0cf8eef-ec2a-4195-99e6-c23140e47d2b"},"outputs":[],"source":["embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")"]},{"cell_type":"markdown","metadata":{"id":"9a643608-e108-4932-8e94-4a0631b874ac"},"source":["### 5.  ベクトルDB Milvusに接続"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"3655cc28-7d24-4437-9e1c-9de6b30392fc"},"outputs":[],"source":["from langchain_milvus import Milvus\n","\n","vector_db = Milvus(\n","    embeddings,\n","    connection_args =my_connection_args,\n","    collection_name = my_collection\n",")"]},{"cell_type":"markdown","metadata":{"id":"906f6ad1-265d-4ab5-a613-143af4093394"},"source":["### 6.  watsonx.ai LLMの取得"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"10cbd80d-950e-40df-aafa-9d83c8023cc6"},"outputs":[],"source":["# 使用するLLMのパラメータ\n","generate_params = {\n","    GenParams.MAX_NEW_TOKENS: 16384,\n","    GenParams.MIN_NEW_TOKENS: 0,\n","    GenParams.DECODING_METHOD: \"greedy\",\n","    GenParams.REPETITION_PENALTY: 1\n","}\n","\n","# LangChainで使うllm\n","custom_llm = WatsonxLLM(\n","    # model_id=\"ibm/granite-3-8b-instruct\", #使用するLLM名\n","    # model_id=\"meta-llama/llama-3-2-3b-instruct\", #使用するLLM名\n","    model_id=\"mistralai/mixtral-8x7b-instruct-v01\",\n","    url=watsonx_url,\n","    apikey=apikey,\n","    project_id=project_id,\n","    params=generate_params,\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"4fa3b011-2ccb-471b-be9f-8d04d91480c2"},"source":["### 8. LangChainのchain作成"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"6daf4afc-ed65-44ed-ab99-0df179a0c89e"},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n","from langchain.schema.runnable import RunnablePassthrough\n","\n","# retrieverは単純なデフォルトのものにします（変えてもOK）\n","retriever = vector_db.as_retriever()\n","\n","# Prompt Templateを設定します。これはmixtral-8x7b-instruct-v01に合わせて作成してあります\n","template = \"\"\"<s> [INST] \n","questionに答えるために、以下のcontextを使用し必ず日本語でanswerを作成してください。\n","必ず⽇本語の文章で回答してください。知ったかぶりをしないでください。\n","回答を書くときは、context内の単語をできるだけ使⽤してください。context中に質問に対する回答が無い低い場合は、「文書中に質問に対する回答が明記されていません。」とだけ回答してください。「文書中に質問に対する回答が明記されていません。」と回答した場合、そこで回答を終わりにしてください。\n","あなたは親切で、礼儀正しく、誠実なアシスタントです。常に安全を保ちながら、できるだけユーザーの役に立つように詳しく回答してください。\n","回答には、有害、非倫理的、⼈種差別的、性差別的、有毒、危険、または違法なコンテンツを含めてはいけません。回答は社会的に偏⾒がなく、本質的に前向きなものであることを確認してください。\n","質問が意味をなさない場合、または事実に⼀貫性がない場合は、正しくないことに答えるのではなく、その理由を説明してください。質問の答えがわからない場合は、誤った情報を共有しないでください。\n","セッションについて回答する場合は、タイトル、時間、会場、概要、レベルを回答してください。回答が200文字以上の場合、回答はなるべく箇条書きを含めてわかりやすく回答してください。\n","[/INST]\n","</s>\n","<s> [INST] 質問が質問の文章ではなく意味がわからない場合[/INST]もう少し詳しく説明していただけますか？</s>\n","\n","context: {context}\n","question: {question}\n","answer: \n","\"\"\"\n","\n","# Prompt Templateを作成します\n","rag_prompt = PromptTemplate.from_template(template)\n","\n","# chainを作成します\n","rag_chain = (\n","    {\"context\": retriever, \"question\": RunnablePassthrough()}\n","    | rag_prompt\n","    | custom_llm\n",")"]},{"cell_type":"markdown","metadata":{"id":"85140aaa-eb55-4185-b0af-c1ba5dc6aabd"},"source":["# 9. gradioでGUI作成(作成中)    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7806e08f-5e34-4c43-a3c7-1ddb55040942"},"outputs":[],"source":["import gradio as gr\n","\n","def echo(message, history):\n","    print(json.dumps(history))\n","\n","    return rag_chain.invoke(message)\n","\n","demo = gr.ChatInterface(fn=echo, type=\"messages\", examples=[\"hello\", \"hola\", \"merhaba\"], title=\"Echo Bot\")\n","demo.launch(share=True)"]},{"cell_type":"markdown","metadata":{"id":"b63ad21a-4bec-40a6-880c-906da3f834e7"},"source":["ベクトルDBに入れていない情報は回答しないようにプロンプトで指示しているので、回答しません。これで不正確な回答が防げます。<br>\n","ただしLLMによってそのような指示を書いても、無視するものもあったり、書き方で回答が変わったりするので、テストでプロンプトを調整したり、必要に応じて不要な回答をなくす後処理を追加してください。\n","\n","\n","---\n","\n","これで「3. ベクトル・データベース Milvusとwatsonx.ai LLMでRAGを構成して、質問をしてみよう!」は完了です。<br>\n","次の「4. ベクトル・データベース Milvusとwatsonx.ai LLMでRAGを構成して、チャットアプリを作成してみよう!」に進んでください。"]}],"metadata":{"kernelspec":{"display_name":"Python 3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
