# æ¼”ç¿’2: Streamlitã§ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œã£ã¦ã¿ã‚‹
æœ€ä½é™ã®ã‚³ãƒ¼ãƒ‰ã§AIæ¨è«–ã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ãŒç¢ºèªã§ããŸã‚‰ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ç™ºå±•ã•ã›ã¦ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«å¤‰ãˆã¦ã¿ã¾ã™ã€‚
ã“ã®æ¼”ç¿’ã§ã¯Streamlitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€å…¥åŠ›ã‚’ãã®ã¾ã¾å‡ºåŠ›ã™ã‚‹Echoãƒœãƒƒãƒˆã‚’ä½œã‚Šã¾ã™ã€‚ãã®å¾Œã€AIæ¨è«–ã‚’çµ„ã¿è¾¼ã‚“ã ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

å‰ææ¡ä»¶:
* IBM watsonx as a Serviceã®ç’°å¢ƒã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨

### Task 1: Hello Streamlit
1. Windowsã®å ´åˆã¯Ubuntuã€Macã®å ´åˆã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ãã¾ã™ã€‚Pythonä»®æƒ³ç’°å¢ƒ venvã«å…¥ã‚Šã¾ã™ã€‚ä»¥é™ã®æ‰‹é †ã§ã‚³ãƒãƒ³ãƒ‰ã¯ã“ã®venvç’°å¢ƒä¸‹ã€~/wxaiãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ¼ã§å®Ÿè¡Œã—ã¾ã™ã€‚

```
cd ~/wxai
source venv/bin/activate
```

2. Streamlitã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```
pip install streamlit
```

3. Streamlitã‚’ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã—ã¾ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«URL: http://localhost:8501 ã«Webã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã€è‡ªå‹•çš„ã«ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãŒé–‹ãã¾ã™ã€‚

```
streamlit hello
```
<img width="1241" alt="wxai06-02-streamlit-hello" src="https://github.com/user-attachments/assets/7bb713dc-2df5-46f3-bcb5-413bcf4a42fd" />

4. Ubuntuã¾ãŸã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«æˆ»ã‚Šã€[ctrl]+[c]ã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã¾ã™ã€‚

### Task 2: Echoãƒœãƒƒãƒˆã®å®Ÿè¡Œã¨æ”¹é€ 

1. Echoãƒœãƒƒãƒˆã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ st_echo.py ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```
wget https://raw.githubusercontent.com/IBM/japan-technology/refs/heads/main/watsonx.ai/dojo/06/st_echo.py
```

ã‚‚ã—ã€MacOSã§wgetã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€wgetã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã‹ã‚‰ã€ä¸Šã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

```
brew install wget
```

2. Visual Studio Codeã§st_echo.pyã‚’é–‹ãã¾ã™ã€‚

```
code st_echo.py
```

3. st_echo.py ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¾ã™ã€‚ã“ã®å¾Œã®ä½œæ¥­ã§ä½¿ã†ã®ã§ã€Visual Stdio Codeã¯é–‹ã„ãŸã¾ã¾ã«ã—ã¦ãã ã•ã„ã€‚

```st_echo.py
# st_echo.py
# Streamlitã‚’ä½¿ã£ã¦ã€å…¥åŠ›å†…å®¹ã‚’ãã®ã¾ã¾å¿œç­”ã™ã‚‹ã‚¨ã‚³ãƒ¼ãƒœãƒƒãƒˆã®ä½œæˆ
# å‚è€ƒ: https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps#build-a-bot-that-mirrors-your-input
import streamlit as st

st.title("Echo botğŸš€")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# React to user input
if prompt := st.chat_input("ä½•ã‹å…¥åŠ›ã—ã¦ãã ã•ã„"):
    # Display user message in chat message container
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    response = f"Echo: {prompt}"
    # Display assistant response in chat message container
    with st.chat_message("assistant"):

```

4. æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å…¥åŠ›ã—ã¦ã€Echoãƒœãƒƒãƒˆã‚’èµ·å‹•ã—ã¾ã™ã€‚

```
streamlit run st_echo.py
```

5. ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãŒèµ·å‹•ã—ã€EchoãƒœãƒƒãƒˆãŒå‹•ãã¾ã™ã€‚ã‚¢ãƒ—ãƒªã«å…¥åŠ›ã—ã¦ã€å†…å®¹ãŒãã®ã¾ã¾å‡ºåŠ›ã•ã‚Œã‚‹ã®ã‚’ç¢ºèªã—ã¾ã™ã€‚

<img width="1241" alt="wxai06-02-echobot" src="https://github.com/user-attachments/assets/0258d524-539c-49af-a532-0ddd7d33b8bb" />

6. å³ä¸Šã®ï¼“ç‚¹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€[Settings]ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™ã€‚
<img width="1241" alt="wxai06-02-settings" src="https://github.com/user-attachments/assets/41a15d29-7622-4e4a-9809-08daa5a5038b" />

7. [Run on save]ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚ªãƒ³ â˜‘ï¸ ã«ã—ã€[x]ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€Settingsç”»é¢ã‚’é–‰ã˜ã¾ã™ã€‚
<img width="1241" alt="wxai06-02-runonsave" src="https://github.com/user-attachments/assets/313f1a4e-63c7-40dc-ae1e-ac3ba3abeae7" />

8. Visual Studio Codeã«æˆ»ã‚Šã€st_echo.pyã®6è¡Œç›®ã‚’å¤‰æ›´ã—ã¦ã€ä¿å­˜ã—ã¾ã™ã€‚

å¤‰æ›´å‰:

```
st.title("Echo botğŸš€")
```

å¤‰æ›´å¾Œ:
```
st.title("ã‚¨ã‚³ãƒ¼ãƒœãƒƒãƒˆğŸ˜ƒ")
```

9. ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ã«æˆ»ã‚Šã€ã‚¨ã‚³ãƒ¼ãƒœãƒƒãƒˆğŸ˜ƒ ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚Streamlitã®ç’°å¢ƒãŒst_echo.pyã®å¤‰æ›´ã‚’ãƒˆãƒªã‚¬ãƒ¼ã«ã‚¢ãƒ—ãƒªã‚’å‹•çš„ã«æ›´æ–°ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚
<img width="1241" alt="wxai06-02-title-changed" src="https://github.com/user-attachments/assets/e51cc7fc-a579-440e-97ce-027ad88d166d" />

10. Ubuntuã¾ãŸã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«æˆ»ã‚Šã€[ctrl]+[c]ã§ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã¾ã™ã€‚

### Task 3: watsonxã«æ¥ç¶šã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å®Ÿè¡Œã¨æ”¹é€ 

1. ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ simplechat.py ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```
wget https://raw.githubusercontent.com/IBM/japan-technology/refs/heads/main/watsonx.ai/dojo/06/simplechat.py
```

2. Visual Studio Codeã§ simplechat.pyã‚’é–‹ãã¾ã™ã€‚

```
code simplechat.py
```

3. simplechat.py ã®ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¾ã™ã€‚[æ¼”ç¿’1](https://github.com/IBM/japan-technology/blob/main/watsonx.ai/dojo/06/01/reame.md}ã§ä½œæˆã—ãŸã€APIã‚­ãƒ¼ã¨Project IDã‚’åˆ©ç”¨ã—ã¦ã€ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãæ›ãˆã¦ã‹ã‚‰ã€ä¿å­˜ã—ã¾ã™ã€‚

```simplechat.py
# simplechat.py
# Streamlitã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä½œæˆ
from ibm_watsonx_ai import APIClient
from ibm_watsonx_ai import Credentials
from ibm_watsonx_ai.foundation_models import ModelInference
import time
import streamlit as st

API_KEY="<APIã‚­ãƒ¼>"
PROJECT_ID="<Project ID>"

st.title("Streamlitã§ãƒãƒ£ãƒƒãƒˆ")

credentials = Credentials(
    url = "https://jp-tok.ml.cloud.ibm.com",
    api_key = API_KEY
)

@st.cache_resource
def connect_watsonx():
    start = time.perf_counter()
    cli = APIClient(credentials)
    end = time.perf_counter()
    st.write("watsonxã¸ã®é€šä¿¡ç¢ºç«‹:"+str(end-start))
    return cli

@st.cache_resource
def load_model():
    start = time.perf_counter()
    m = ModelInference(
            model_id="ibm/granite-3-8b-instruct",
            api_client=connect_watsonx(),
            project_id=PROJECT_ID,
            params = {
                "max_new_tokens": 600
            }
        )
    end = time.perf_counter()
    st.write("LLMã®è¨­å®šå®Œäº†:"+str(end-start))
    return m


model = load_model()


if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


if prompt:= st.chat_input("ä½•ã‹å…¥åŠ›ã—ã¦ãã ã•ã„"):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        generated_stream = model.generate_text_stream(prompt)
        response = st.write_stream(generated_stream)
        st.session_state.messages.append({"role": "assistant", "content": response})
```

4. æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å…¥åŠ›ã—ã¦ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’èµ·å‹•ã—ã¾ã™ã€‚

```
streamlit run simplechat.py
```

5. ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãŒç«‹ã¡ä¸ŠãŒã‚Šã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒå‹•ä½œã—ã¾ã™ã€‚
<img width="1241" alt="wxai06-02-simplechat" src="https://github.com/user-attachments/assets/8f76a99c-39ce-4766-a89f-a6e828375b11" />


6. ç”»é¢ä¸‹å´ã®å…¥åŠ›æ¬„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¾ã™ã€‚

```
C#ã‚’ä½¿ã£ã¦ONNXãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
```
<img width="1241" alt="wxai06-02-prompt" src="https://github.com/user-attachments/assets/7fdcc8c5-6e46-4ddd-8390-84883bf6cbc7" />

7. [Enter]ã‚­ãƒ¼ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚çµæœãŒã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚
<img width="1281" alt="wxai06-02-generated" src="https://github.com/user-attachments/assets/76ac4d2a-212a-4de0-a0d6-fc6531fe0800" />

* watsonxã®Modelã‚¯ãƒ©ã‚¹ã®generate_text_streamãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ã¯[ã“ã¡ã‚‰](https://ibm.github.io/watson-machine-learning-sdk/model.html)ã‹ã‚‰ç¢ºèªã§ãã¾ã™ã€‚

8. ä»–ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ã€å®Ÿè¡Œçµæœã‚’ç¢ºèªã—ã¾ã™ã€‚

```
IBM Graniteã¨ã¯ä½•ã‹æ•™ãˆã¦ãã ã•ã„
```



